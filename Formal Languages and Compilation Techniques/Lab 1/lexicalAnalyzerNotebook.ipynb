{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'c.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPartOfOperator(char): \n",
    "    for op in operators: \n",
    "        if char in op: \n",
    "            return True \n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEscapedQuote(line, index):\n",
    "    return False if index == 0 else line[index -1] == '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStringToken(line, index):\n",
    "    token = ''\n",
    "    quoteCount = 0\n",
    "    \n",
    "    while index < len(line) and quoteCount < 2:\n",
    "        if line[index] == '\"' and not isEscapedQuote(line, index):\n",
    "            quoteCount += 1 \n",
    "        token += line[index]\n",
    "        index += 1\n",
    "        \n",
    "    return token, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOperatorToken(line, index):\n",
    "    token = ''\n",
    "    \n",
    "    while index < len(line) and isPartOfOperator(line[index]):\n",
    "        token += line[index]\n",
    "        index += 1 \n",
    "        \n",
    "    return token, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenGenerator(line, separators): \n",
    "    token = ''\n",
    "    index = 0\n",
    "    \n",
    "    while index < len(line):\n",
    "        if line[index] == '\"': \n",
    "            if token: \n",
    "                yield token\n",
    "            token, index = getStringToken(line, index)\n",
    "            yield token\n",
    "            token = ''\n",
    "            \n",
    "        elif isPartOfOperator(line[index]):\n",
    "            if token: \n",
    "                yield token\n",
    "            token, index = getOperatorToken(line, index)\n",
    "            yield token\n",
    "            token = ''\n",
    "        \n",
    "        elif line[index] in separators:\n",
    "            if token: \n",
    "                yield token\n",
    "            token, index = line[index], index + 1\n",
    "            yield token\n",
    "            token = ''\n",
    "            \n",
    "        else:\n",
    "            token += line[index]\n",
    "            index += 1 \n",
    "    if token: \n",
    "        yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([ token for token in tokenGenerator('(a+b&&c/2<=8+\"a<=b||2\")', separators)])\n",
    "print([ token for token in tokenGenerator('something', separators)])\n",
    "print([ token for token in tokenGenerator('\" \\\\\"Hello\\\\\" \"', separators)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators = ['[', ']', '{', '}', '(', ')', ';', ' '] \n",
    "operators = ['+', '-', '*', '/', '<', '<=', '=', '>=', '>', '>>', '<<', '==', '&&', '||', '!', '&']\n",
    "reservedWords = ['int', 'char', 'bool', 'float', 'array', 'struct', 'if', 'else', 'for', 'while', 'cout']\n",
    "\n",
    "everything = separators + operators + reservedWords\n",
    "codification = dict( [ [everything[i], i + 2] for i in range(len(everything))])\n",
    "codification['identifier'] = 0\n",
    "codification['constant'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable(): \n",
    "    def __init__(self):\n",
    "        self.__content = []\n",
    "       \n",
    "    def __search(self, key):\n",
    "        return self.__content.index(key) if key in self.__content else None \n",
    "    \n",
    "    def add(self, value):\n",
    "        key = self.__hash(value)\n",
    "        \n",
    "        index = self.__search(key)\n",
    "        \n",
    "        if index is not None: \n",
    "            collisionList = self.__content[index]\n",
    "            if value not in collisionList: \n",
    "                collisionList.append(value)\n",
    "            return (index, collisionList.index(value))\n",
    "        else: \n",
    "            self.__content.append((key, [value]))\n",
    "            cl_index = 0\n",
    "            index = len(self.__content) - 1\n",
    "            \n",
    "        return (index, cl_index)\n",
    "        \n",
    "    def getId(self, value):\n",
    "        key = self.__hash(value)\n",
    "        index = self.__search(key)\n",
    "        \n",
    "        if index is None: \n",
    "            return None \n",
    "        \n",
    "        collisionList = self.__content[index]\n",
    "        \n",
    "        if value not in collisionList:\n",
    "            return None \n",
    "        \n",
    "        cl_index = collisionList.index(value)\n",
    "        \n",
    "        return (index, cl_index)\n",
    "    \n",
    "    def __hash(self, value):\n",
    "        sum = 0 \n",
    "        for char in value:\n",
    "            sum += ord(char) \n",
    "        \n",
    "        return sum / len(value)\n",
    "    \n",
    "    def __str__(self): \n",
    "        return str(self.__content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymbolTable():\n",
    "    def __init__(self):\n",
    "        self.__hashTable = HashTable()\n",
    "        self.__content = dict() \n",
    "        self.__count = -1\n",
    "        \n",
    "    def add(self, value):\n",
    "        return self.__hashTable.add(value)\n",
    "    \n",
    "    def get(self, value):\n",
    "        return self.__hashTable.getId(value)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.__hashTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramInternalForm: \n",
    "    def __init__(self):\n",
    "        self.__content = []\n",
    "        \n",
    "    def add(self, code, id):\n",
    "        self.__content.append((code, id))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.__content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isIdentifier(token): \n",
    "    return re.match(r'^[a-zA-Z]([a-zA-Z]|[0-9]|_){,8}$', token) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isConstant(token):\n",
    "    return re.match('^(0|[\\+\\-]?[1-9][0-9]*)$|^\\'.\\'$|^\\\".*\\\"$', token) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(fileName, 'r')\n",
    "for line in file: \n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fileName, 'r') as file: \n",
    "    for line in file: \n",
    "        print([token for token in tokenGenerator(line, separators)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifierTable = SymbolTable()\n",
    "constantsTable = SymbolTable()\n",
    "pif = ProgramInternalForm()\n",
    "\n",
    "with open(fileName, 'r') as file: \n",
    "    lineNo = 0\n",
    "    for line in file:\n",
    "        lineNo += 1 \n",
    "        for token in tokenGenerator(line[0:-1], separators):  \n",
    "            if token in separators + operators + reservedWords: \n",
    "                pif.add(codification[token], -1)\n",
    "            elif isIdentifier(token): \n",
    "                id = identifierTable.add(token)\n",
    "                pif.add(codification['identifier'], id)\n",
    "            elif isConstant(token): \n",
    "                id = constantsTable.add(token)\n",
    "                pif.add(codification['constant'], id)\n",
    "            else:\n",
    "                raise Exception('Unknown token ' + token + ' at line ' + str(lineNo)) \n",
    "                \n",
    "print('Program Internal Form: \\n', pif)\n",
    "print('Identifier Table: \\n', identifierTable) \n",
    "print('Constants Table: \\n', constantsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
