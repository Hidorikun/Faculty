{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, weights_count):\n",
    "        self.weights = [ (random()*2-1) for _ in range(weights_count) ] \n",
    "#         self.weights = [ random() for _ in range(weights_count) ] \n",
    "        self.weights_count = weights_count\n",
    "        self.bias    = random()\n",
    "        self.output  = None\n",
    "        self.error   = None\n",
    "        \n",
    "    def get_output(self, input_values):\n",
    "        self.output = self.bias\n",
    "        \n",
    "        for index in range(len(self.weights)):\n",
    "            \n",
    "            self.output += self.weights[index] * input_values[index]\n",
    "            \n",
    "#         for weight, value in zip(self.weights, input_values):\n",
    "#             self.output += weight * value\n",
    "        return self.output\n",
    "    \n",
    "    def set_error(self, error):\n",
    "        self.error = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: \n",
    " \n",
    "    def __init__(self, \n",
    "                 neurons_count, \n",
    "                 activation_function, \n",
    "                 derivative_function, \n",
    "                 weights_count):\n",
    "        self.neurons_count = neurons_count\n",
    "        self.activation_function = activation_function\n",
    "        self.derivative_function = derivative_function\n",
    "        self.neurons = [ Neuron(weights_count) for _ in range(neurons_count)]\n",
    "        \n",
    "    def activate(self, input_values):\n",
    "        for neuron in self.neurons: \n",
    "#             print(neuron.bias)\n",
    "#             print(neuron.get_output(input_values))\n",
    "#             print()\n",
    "            \n",
    "            neuron.output = self.activation_function(neuron.get_output(input_values))\n",
    "            \n",
    "    def get_output(self):\n",
    "        return [ neuron.output for neuron in self.neurons ]\n",
    "    \n",
    "    def update_layer_weights(self, input_values, learning_rate):\n",
    "        for neuron in self.neurons: \n",
    "            for index in range(neuron.weights_count):\n",
    "                neuron.weights[index] += learning_rate * neuron.error * input_values[index]\n",
    "            neuron.bias += learning_rate * neuron.error\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer(Layer):\n",
    "    def __init__(self, neurons_count, \n",
    "                 activation_function, \n",
    "                 derivative_function, \n",
    "                 weights_count):\n",
    "        Layer.__init__(self, neurons_count, activation_function, derivative_function, weights_count)\n",
    "    \n",
    "    def compute_error(self, next_layer):\n",
    "        for index in range(self.neurons_count):\n",
    "#             print('intra in asta')\n",
    "            delta = 0.0 \n",
    "            for neuron in next_layer.neurons:\n",
    "                delta += neuron.weights[index] * neuron.error\n",
    "            error = self.derivative_function(self.neurons[index].output) * delta\n",
    "            self.neurons[index].set_error(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    def __init__(self, neurons_count, \n",
    "                 activation_function, \n",
    "                 derivative_function, \n",
    "                 weights_count):\n",
    "        \n",
    "        Layer.__init__(self, neurons_count, activation_function, derivative_function, weights_count)\n",
    "    \n",
    "    def compute_error(self, expected):\n",
    "#         print('merge compute pe output')\n",
    "        for index in range(len(self.neurons)):\n",
    "            delta = expected[index] - self.neurons[index].output\n",
    "            self.neurons[index].set_error(delta * self.derivative_function(self.neurons[index].output))\n",
    "            \n",
    "#         for value, neuron in zip(expected, self.neurons):\n",
    "#             print('intra in astalalta')\n",
    "#             delta = value - neuron.output\n",
    "#             neuron.set_error(delta * self.derivative_function(neuron.output))\n",
    "#             print(neuron.error)\n",
    "#         for neuron in self.neurons:\n",
    "#             print(neuron.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self,\n",
    "                layer_count, \n",
    "                neuron_count, \n",
    "                activation_function, \n",
    "                derivative_function, \n",
    "                input_count, \n",
    "                class_count):\n",
    "        self.layers = self.initialize_layers(layer_count, \n",
    "                                        neuron_count, \n",
    "                                        activation_function, \n",
    "                                        derivative_function, \n",
    "                                        input_count, \n",
    "                                        class_count)\n",
    "        self.class_count = class_count\n",
    "        self.learning_rate = 0.3\n",
    "        \n",
    "    def forward(self, input_values):\n",
    "        inputs = input_values\n",
    "        for layer in self.layers:\n",
    "            layer.activate(inputs)\n",
    "            inputs = layer.get_output()\n",
    "        \n",
    "    def backward(self, input_values, expected):\n",
    "        self.layers[-1].compute_error(expected)\n",
    "        self.layers[-1].update_layer_weights(input_values, self.learning_rate)\n",
    "        \n",
    "        for index in reversed(range(len(self.layers) - 1)):\n",
    "            self.layers[index].compute_error(self.layers[index + 1])\n",
    "        \n",
    "        self.layers[0].update_layer_weights(input_values, self.learning_rate)\n",
    "        \n",
    "#         print('hello there')\n",
    "        \n",
    "        for index in range(1, len(self.layers)):\n",
    "            self.layers[index].update_layer_weights(self.layers[index - 1].get_output(), self.learning_rate)\n",
    "        \n",
    "    def initialize_layers(self, layer_count, neuron_count, activation_function, derivative_function, input_count, class_count):\n",
    "        layers = [ HiddenLayer(neuron_count, activation_function, derivative_function, input_count) ]\n",
    "        for _ in range(layer_count - 1):\n",
    "            layers.append(HiddenLayer(neuron_count, activation_function, derivative_function, len(layers[-1].neurons)))\n",
    "        layers.append( OutputLayer(class_count, activation_function, derivative_function, len(layers[-1].neurons)) )\n",
    "        \n",
    "        return layers\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Application:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_count = 3  \n",
    "        self.data = pd.read_csv(\"dataset.csv\")\n",
    "        self.columns = list(self.data)\n",
    "        self.classes = self.columns.pop()\n",
    "        self.normalize_data()\n",
    "        self.train_data = []\n",
    "        self.test_data  = []\n",
    "        self.split_data()\n",
    "        self.network = Network(\n",
    "            neuron_count=15, \n",
    "            layer_count=2, \n",
    "            activation_function=lambda x: 1/(1 + math.exp(-x)), \n",
    "            derivative_function=lambda x: x * (1-x), \n",
    "            input_count=len(self.columns),\n",
    "            class_count=self.class_count\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        iteration_count = 10\n",
    "        for _ in range(iteration_count):\n",
    "            self.train_data = self.train_data.sample(frac=1)\n",
    "            for _, example in self.train_data.iterrows():\n",
    "                example = example.tolist()\n",
    "                expected_class = example.pop()\n",
    "                self.network.forward(example)\n",
    "                expected = [ 1 if index == expected_class - 1 else 0 for index in range(self.class_count)]\n",
    "                self.network.backward(example, expected)\n",
    "#         print(\"hello\")\n",
    "                \n",
    "    def test(self):\n",
    "        correct_count = 0 \n",
    "        for _, row in self.test_data.iterrows():\n",
    "            row = row.tolist()\n",
    "            expected_class = row.pop()\n",
    "            predicted_class = self.classify(row) + 1\n",
    "#             print(predicted_class)\n",
    "#             print(expected_class)\n",
    "#             print()\n",
    "            if predicted_class == expected_class:\n",
    "                correct_count += 1\n",
    "                \n",
    "        return float(correct_count) / float(len(self.test_data))\n",
    "    \n",
    "    def classify(self, input_values):\n",
    "#             print(type(input_values))\n",
    "            self.network.forward(input_values)\n",
    "            output = self.network.layers[-1].get_output()\n",
    "            max_index = np.argmax(output)\n",
    "            return max_index\n",
    "            \n",
    "    def normalize_data(self):\n",
    "        for c in self.columns:\n",
    "            column = [float(item) for item in self.data[c]]\n",
    "            minimum = min(column)\n",
    "            maximum = max(column)\n",
    "            for index in range(self.data.shape[0]):\n",
    "                old_value = float(self.data.iloc[index][c])\n",
    "                if (maximum == minimum):\n",
    "                    new_value = 0.5\n",
    "                else:\n",
    "                    new_value = (old_value - minimum) / (maximum - minimum)\n",
    "                self.data.ix[index, c] = new_value\n",
    "                \n",
    "    def split_data(self):\n",
    "        self.train_data, self.test_data = train_test_split(self.data, test_size = 0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"dataset.csv\")\n",
    "# # data = data.sample(frac=1)\n",
    "# for example in data.iterrows():\n",
    "# #     print(type(example[1]))\n",
    "#     print(example)\n",
    "#     print(example[1].tolist())\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Application() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
